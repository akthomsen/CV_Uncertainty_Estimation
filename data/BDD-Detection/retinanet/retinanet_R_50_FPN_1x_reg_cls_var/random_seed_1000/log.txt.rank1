[05/01 11:30:25] detectron2 INFO: Rank of current process: 1. World size: 2
[05/01 11:30:26] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.17 (default, Apr  9 2025, 14:45:56) [GCC 11.4.0]
numpy                   1.21.6
detectron2              0.6 @/home/cv09f25/.pyenv/versions/3.7.17/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu113 @/home/cv09f25/.pyenv/versions/3.7.17/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          550.90.07
CUDA_HOME               /opt/cuda-11.3
Pillow                  9.5.0
torchvision             0.11.0+cu113 @/home/cv09f25/.pyenv/versions/3.7.17/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.11.0
----------------------  ------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[05/01 11:30:26] detectron2 INFO: Command line arguments: Namespace(config_file='/home/cv09f25/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var.yaml', dataset_dir='BDD_DATASET_ROOT', dist_url='tcp://127.0.0.1:53711', eval_only=False, inference_config='', iou_correct=0.7, iou_min=0.1, machine_rank=0, min_allowed_score=0.0, num_gpus=2, num_machines=1, opts=[], random_seed=1000, resume=True, test_dataset='')
[05/01 11:30:26] detectron2 INFO: Contents of args.config_file=/home/cv09f25/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var.yaml:
[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mBase-BDD-RetinaNet.yaml[39m[38;5;186m"[39m

[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mPROBABILISTIC_MODELING[39m[38;5;15m:[39m
[38;5;15m        [39m[38;5;245m# One of the following Loss types: loss_attenuation'.[39m
[38;5;15m        [39m[38;5;204mCLS_VAR_LOSS[39m[38;5;15m:[39m
[38;5;15m            [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mloss_attenuation[39m[38;5;186m'[39m
[38;5;15m            [39m[38;5;204mNUM_SAMPLES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;15m        [39m[38;5;245m# One of the following Loss types: 'none' or 'negative_log_likelihood', 'second_moment_matching', 'energy_loss'.[39m
[38;5;15m        [39m[38;5;204mBBOX_COV_LOSS[39m[38;5;15m:[39m
[38;5;15m            [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mnegative_log_likelihood[39m[38;5;186m'[39m
[38;5;15m            [39m[38;5;204mCOVARIANCE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdiagonal[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# One of the following: 'full', 'diagonal'[39m

[05/01 11:30:27] detectron2.engine.defaults INFO: Model:
ProbabilisticRetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): ProbabilisticRetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (cls_var): Conv2d(256, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_cov): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[05/01 11:30:31] detectron2.data.datasets.coco INFO: Loading BDD_DATASET_ROOT/labels/train_coco_format.json takes 3.89 seconds.
[05/01 11:30:31] detectron2.data.datasets.coco INFO: Loaded 69863 images in COCO format from BDD_DATASET_ROOT/labels/train_coco_format.json
[05/01 11:30:34] detectron2.data.build INFO: Removed 458 images with no usable annotations. 69405 images left.
[05/01 11:30:36] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    car     | 713211       |    bus     | 11672        |   truck    | 29971        |
|   person   | 91349        |   rider    | 4517         |    bike    | 7210         |
|   motor    | 3002         |            |              |            |              |
|   total    | 860932       |            |              |            |              |[0m
[05/01 11:30:36] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720,), max_size=1333, sample_style='choice'), RandomFlip()]
[05/01 11:30:36] detectron2.data.build INFO: Using training sampler TrainingSampler
[05/01 11:30:36] detectron2.data.common INFO: Serializing 69405 elements to byte tensors and concatenating them all ...
[05/01 11:30:37] detectron2.data.common INFO: Serialized dataset takes 62.23 MiB
[05/01 11:30:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[05/01 11:30:37] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[05/01 11:30:37] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[05/01 11:30:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mhead.bbox_cov.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[34mhead.cls_var.{bias, weight}[0m
[05/01 11:30:37] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[05/01 11:30:37] detectron2.engine.train_loop INFO: Starting training from iteration 0
[05/02 05:15:57] detectron2.engine.hooks INFO: Overall training speed: 89998 iterations in 17:45:03 (0.7101 s / it)
[05/02 05:15:57] detectron2.engine.hooks INFO: Total training time: 17:45:09 (0:00:06 on hooks)
[05/02 05:15:58] detectron2.data.datasets.coco INFO: Loaded 10000 images in COCO format from BDD_DATASET_ROOT/labels/val_coco_format.json
[05/02 05:15:58] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    car     | 102506       |    bus     | 1597         |   truck    | 4245         |
|   person   | 13262        |   rider    | 649          |    bike    | 1007         |
|   motor    | 452          |            |              |            |              |
|   total    | 123718       |            |              |            |              |[0m
[05/02 05:15:58] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[05/02 05:15:58] detectron2.data.common INFO: Serializing 10000 elements to byte tensors and concatenating them all ...
[05/02 05:15:58] detectron2.data.common INFO: Serialized dataset takes 8.92 MiB
[05/02 05:15:58] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[05/02 05:15:59] detectron2.evaluation.evaluator INFO: Start inference on 5000 batches
[05/02 05:16:13] detectron2.evaluation.evaluator INFO: Inference done 11/5000. Dataloading: 0.0580 s/iter. Inference: 0.0950 s/iter. Eval: 0.0002 s/iter. Total: 0.1532 s/iter. ETA=0:12:44
[05/02 05:16:18] detectron2.evaluation.evaluator INFO: Inference done 62/5000. Dataloading: 0.0072 s/iter. Inference: 0.0976 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:08:38
[05/02 05:16:23] detectron2.evaluation.evaluator INFO: Inference done 114/5000. Dataloading: 0.0044 s/iter. Inference: 0.0968 s/iter. Eval: 0.0002 s/iter. Total: 0.1014 s/iter. ETA=0:08:15
[05/02 05:16:28] detectron2.evaluation.evaluator INFO: Inference done 166/5000. Dataloading: 0.0034 s/iter. Inference: 0.0965 s/iter. Eval: 0.0002 s/iter. Total: 0.1001 s/iter. ETA=0:08:03
[05/02 05:16:33] detectron2.evaluation.evaluator INFO: Inference done 218/5000. Dataloading: 0.0029 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0994 s/iter. ETA=0:07:55
[05/02 05:16:38] detectron2.evaluation.evaluator INFO: Inference done 270/5000. Dataloading: 0.0026 s/iter. Inference: 0.0962 s/iter. Eval: 0.0002 s/iter. Total: 0.0990 s/iter. ETA=0:07:48
[05/02 05:16:43] detectron2.evaluation.evaluator INFO: Inference done 322/5000. Dataloading: 0.0024 s/iter. Inference: 0.0962 s/iter. Eval: 0.0002 s/iter. Total: 0.0988 s/iter. ETA=0:07:42
[05/02 05:16:48] detectron2.evaluation.evaluator INFO: Inference done 374/5000. Dataloading: 0.0022 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0986 s/iter. ETA=0:07:36
[05/02 05:16:54] detectron2.evaluation.evaluator INFO: Inference done 426/5000. Dataloading: 0.0021 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0985 s/iter. ETA=0:07:30
[05/02 05:16:59] detectron2.evaluation.evaluator INFO: Inference done 478/5000. Dataloading: 0.0020 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0984 s/iter. ETA=0:07:24
[05/02 05:17:04] detectron2.evaluation.evaluator INFO: Inference done 530/5000. Dataloading: 0.0020 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0983 s/iter. ETA=0:07:19
[05/02 05:17:09] detectron2.evaluation.evaluator INFO: Inference done 581/5000. Dataloading: 0.0019 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.0985 s/iter. ETA=0:07:15
[05/02 05:17:14] detectron2.evaluation.evaluator INFO: Inference done 633/5000. Dataloading: 0.0019 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0985 s/iter. ETA=0:07:10
[05/02 05:17:19] detectron2.evaluation.evaluator INFO: Inference done 685/5000. Dataloading: 0.0018 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0984 s/iter. ETA=0:07:04
[05/02 05:17:24] detectron2.evaluation.evaluator INFO: Inference done 736/5000. Dataloading: 0.0018 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.0984 s/iter. ETA=0:06:59
[05/02 05:17:29] detectron2.evaluation.evaluator INFO: Inference done 787/5000. Dataloading: 0.0018 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.0984 s/iter. ETA=0:06:54
[05/02 05:17:34] detectron2.evaluation.evaluator INFO: Inference done 839/5000. Dataloading: 0.0017 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.0984 s/iter. ETA=0:06:49
[05/02 05:17:39] detectron2.evaluation.evaluator INFO: Inference done 891/5000. Dataloading: 0.0017 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.0983 s/iter. ETA=0:06:44
[05/02 05:17:44] detectron2.evaluation.evaluator INFO: Inference done 943/5000. Dataloading: 0.0017 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0983 s/iter. ETA=0:06:38
[05/02 05:17:49] detectron2.evaluation.evaluator INFO: Inference done 995/5000. Dataloading: 0.0017 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0982 s/iter. ETA=0:06:33
[05/02 05:17:54] detectron2.evaluation.evaluator INFO: Inference done 1047/5000. Dataloading: 0.0016 s/iter. Inference: 0.0963 s/iter. Eval: 0.0002 s/iter. Total: 0.0982 s/iter. ETA=0:06:28
[05/02 05:17:59] detectron2.evaluation.evaluator INFO: Inference done 1099/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0002 s/iter. Total: 0.0981 s/iter. ETA=0:06:22
[05/02 05:18:04] detectron2.evaluation.evaluator INFO: Inference done 1151/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0002 s/iter. Total: 0.0981 s/iter. ETA=0:06:17
[05/02 05:18:10] detectron2.evaluation.evaluator INFO: Inference done 1203/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0002 s/iter. Total: 0.0981 s/iter. ETA=0:06:12
[05/02 05:18:15] detectron2.evaluation.evaluator INFO: Inference done 1253/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0982 s/iter. ETA=0:06:07
[05/02 05:18:20] detectron2.evaluation.evaluator INFO: Inference done 1305/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:06:02
[05/02 05:18:25] detectron2.evaluation.evaluator INFO: Inference done 1357/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:57
[05/02 05:18:30] detectron2.evaluation.evaluator INFO: Inference done 1409/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:52
[05/02 05:18:35] detectron2.evaluation.evaluator INFO: Inference done 1461/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:47
[05/02 05:18:40] detectron2.evaluation.evaluator INFO: Inference done 1513/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:42
[05/02 05:18:45] detectron2.evaluation.evaluator INFO: Inference done 1565/5000. Dataloading: 0.0016 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:36
[05/02 05:18:50] detectron2.evaluation.evaluator INFO: Inference done 1617/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:31
[05/02 05:18:55] detectron2.evaluation.evaluator INFO: Inference done 1669/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:26
[05/02 05:19:00] detectron2.evaluation.evaluator INFO: Inference done 1720/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:21
[05/02 05:19:05] detectron2.evaluation.evaluator INFO: Inference done 1772/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:16
[05/02 05:19:10] detectron2.evaluation.evaluator INFO: Inference done 1824/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:11
[05/02 05:19:16] detectron2.evaluation.evaluator INFO: Inference done 1876/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:05:06
[05/02 05:19:21] detectron2.evaluation.evaluator INFO: Inference done 1927/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:05:01
[05/02 05:19:26] detectron2.evaluation.evaluator INFO: Inference done 1979/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:04:56
[05/02 05:19:31] detectron2.evaluation.evaluator INFO: Inference done 2030/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:04:51
[05/02 05:19:36] detectron2.evaluation.evaluator INFO: Inference done 2082/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:46
[05/02 05:19:41] detectron2.evaluation.evaluator INFO: Inference done 2134/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:41
[05/02 05:19:46] detectron2.evaluation.evaluator INFO: Inference done 2186/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:36
[05/02 05:19:51] detectron2.evaluation.evaluator INFO: Inference done 2238/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:30
[05/02 05:19:56] detectron2.evaluation.evaluator INFO: Inference done 2290/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:25
[05/02 05:20:01] detectron2.evaluation.evaluator INFO: Inference done 2342/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:20
[05/02 05:20:06] detectron2.evaluation.evaluator INFO: Inference done 2394/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:15
[05/02 05:20:11] detectron2.evaluation.evaluator INFO: Inference done 2446/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:10
[05/02 05:20:17] detectron2.evaluation.evaluator INFO: Inference done 2498/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:05
[05/02 05:20:22] detectron2.evaluation.evaluator INFO: Inference done 2550/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:04:00
[05/02 05:20:27] detectron2.evaluation.evaluator INFO: Inference done 2601/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:03:55
[05/02 05:20:32] detectron2.evaluation.evaluator INFO: Inference done 2653/5000. Dataloading: 0.0015 s/iter. Inference: 0.0963 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:03:50
[05/02 05:20:37] detectron2.evaluation.evaluator INFO: Inference done 2705/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:45
[05/02 05:20:42] detectron2.evaluation.evaluator INFO: Inference done 2757/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:39
[05/02 05:20:47] detectron2.evaluation.evaluator INFO: Inference done 2809/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:34
[05/02 05:20:52] detectron2.evaluation.evaluator INFO: Inference done 2861/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:29
[05/02 05:20:57] detectron2.evaluation.evaluator INFO: Inference done 2913/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:24
[05/02 05:21:02] detectron2.evaluation.evaluator INFO: Inference done 2965/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:19
[05/02 05:21:07] detectron2.evaluation.evaluator INFO: Inference done 3017/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:03:14
[05/02 05:21:12] detectron2.evaluation.evaluator INFO: Inference done 3069/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:03:09
[05/02 05:21:17] detectron2.evaluation.evaluator INFO: Inference done 3121/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:03:04
[05/02 05:21:22] detectron2.evaluation.evaluator INFO: Inference done 3171/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:02:59
[05/02 05:21:27] detectron2.evaluation.evaluator INFO: Inference done 3223/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:02:54
[05/02 05:21:32] detectron2.evaluation.evaluator INFO: Inference done 3275/5000. Dataloading: 0.0015 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0980 s/iter. ETA=0:02:48
[05/02 05:21:37] detectron2.evaluation.evaluator INFO: Inference done 3327/5000. Dataloading: 0.0014 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:43
[05/02 05:21:42] detectron2.evaluation.evaluator INFO: Inference done 3379/5000. Dataloading: 0.0014 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:38
[05/02 05:21:48] detectron2.evaluation.evaluator INFO: Inference done 3431/5000. Dataloading: 0.0014 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:33
[05/02 05:21:53] detectron2.evaluation.evaluator INFO: Inference done 3483/5000. Dataloading: 0.0014 s/iter. Inference: 0.0962 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:28
[05/02 05:21:58] detectron2.evaluation.evaluator INFO: Inference done 3535/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:23
[05/02 05:22:03] detectron2.evaluation.evaluator INFO: Inference done 3587/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0003 s/iter. Total: 0.0979 s/iter. ETA=0:02:18
[05/02 05:22:08] detectron2.evaluation.evaluator INFO: Inference done 3639/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0979 s/iter. ETA=0:02:13
[05/02 05:22:13] detectron2.evaluation.evaluator INFO: Inference done 3691/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0979 s/iter. ETA=0:02:08
[05/02 05:22:18] detectron2.evaluation.evaluator INFO: Inference done 3743/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:02:02
[05/02 05:22:23] detectron2.evaluation.evaluator INFO: Inference done 3795/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:57
[05/02 05:22:28] detectron2.evaluation.evaluator INFO: Inference done 3847/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:52
[05/02 05:22:33] detectron2.evaluation.evaluator INFO: Inference done 3899/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:47
[05/02 05:22:38] detectron2.evaluation.evaluator INFO: Inference done 3951/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:42
[05/02 05:22:43] detectron2.evaluation.evaluator INFO: Inference done 4003/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:37
[05/02 05:22:48] detectron2.evaluation.evaluator INFO: Inference done 4055/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:32
[05/02 05:22:53] detectron2.evaluation.evaluator INFO: Inference done 4107/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:27
[05/02 05:22:58] detectron2.evaluation.evaluator INFO: Inference done 4159/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:22
[05/02 05:23:03] detectron2.evaluation.evaluator INFO: Inference done 4211/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:17
[05/02 05:23:08] detectron2.evaluation.evaluator INFO: Inference done 4263/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:12
[05/02 05:23:13] detectron2.evaluation.evaluator INFO: Inference done 4315/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:06
[05/02 05:23:18] detectron2.evaluation.evaluator INFO: Inference done 4367/5000. Dataloading: 0.0014 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.0978 s/iter. ETA=0:01:01
[05/02 05:23:24] detectron2.evaluation.evaluator INFO: Inference done 4418/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:56
[05/02 05:23:29] detectron2.evaluation.evaluator INFO: Inference done 4470/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:51
[05/02 05:23:34] detectron2.evaluation.evaluator INFO: Inference done 4522/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:46
[05/02 05:23:39] detectron2.evaluation.evaluator INFO: Inference done 4574/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:41
[05/02 05:23:44] detectron2.evaluation.evaluator INFO: Inference done 4626/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:36
[05/02 05:23:49] detectron2.evaluation.evaluator INFO: Inference done 4678/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:31
[05/02 05:23:54] detectron2.evaluation.evaluator INFO: Inference done 4730/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0978 s/iter. ETA=0:00:26
[05/02 05:23:59] detectron2.evaluation.evaluator INFO: Inference done 4782/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0977 s/iter. ETA=0:00:21
[05/02 05:24:04] detectron2.evaluation.evaluator INFO: Inference done 4834/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0977 s/iter. ETA=0:00:16
[05/02 05:24:09] detectron2.evaluation.evaluator INFO: Inference done 4886/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0977 s/iter. ETA=0:00:11
[05/02 05:24:14] detectron2.evaluation.evaluator INFO: Inference done 4938/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0977 s/iter. ETA=0:00:06
[05/02 05:24:19] detectron2.evaluation.evaluator INFO: Inference done 4990/5000. Dataloading: 0.0014 s/iter. Inference: 0.0960 s/iter. Eval: 0.0003 s/iter. Total: 0.0977 s/iter. ETA=0:00:00
[05/02 05:24:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:08:08.434293 (0.097785 s / iter per device, on 2 devices)
[05/02 05:24:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:59 (0.095988 s / iter per device, on 2 devices)
